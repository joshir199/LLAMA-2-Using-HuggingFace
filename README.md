# llama-2-v1
Testing and creating end point inference of Llama 2 open source model for text completion and chatbot 

# Quantized version
4-bit quantization is applied for inference on CPU power

# Code Results
For Text Completion:
input : "where in the world is Seville?"
output : I'm not sure if I'm going to be able to make it to the next meeting. I'm going to be in Seville, Spain for a week. I'm not sure if I'll have internet access. I'll try to check in, but I'm not sure if I'll be able to post.


![Alt text](//C:/Users/Raushan Joshi/Downloads/llama-main/model_and_tokenizer_download_for_llama_13b_hf.png "Optional title")
